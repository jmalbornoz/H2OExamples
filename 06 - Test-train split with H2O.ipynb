{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting in H2O\n",
    "## Jose M Albornoz\n",
    "### December 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to do a train-test split in H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\n",
      "  Starting server from c:\\users\\albornoj\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\AlbornoJ\\AppData\\Local\\Temp\\tmpngu88mf1\n",
      "  JVM stdout: C:\\Users\\AlbornoJ\\AppData\\Local\\Temp\\tmpngu88mf1\\h2o_AlbornoJ_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\AlbornoJ\\AppData\\Local\\Temp\\tmpngu88mf1\\h2o_AlbornoJ_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>12 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_AlbornoJ_oapsnj</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.531 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.1 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         06 secs\n",
       "H2O cluster timezone:       Europe/London\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.2\n",
       "H2O cluster version age:    12 days\n",
       "H2O cluster name:           H2O_from_python_AlbornoJ_oapsnj\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.531 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.1 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Import Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "iris = h2o.import_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a 80-20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = iris.split_frame([0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>sepal_len         </th><th>sepal_wid          </th><th>petal_len         </th><th>petal_wid         </th><th>class      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>real              </td><td>real               </td><td>real              </td><td>real              </td><td>enum       </td></tr>\n",
       "<tr><td>mins   </td><td>4.4               </td><td>2.0                </td><td>1.0               </td><td>0.1               </td><td>           </td></tr>\n",
       "<tr><td>mean   </td><td>5.854621848739495 </td><td>3.034453781512605  </td><td>3.8226890756302523</td><td>1.2201680672268904</td><td>           </td></tr>\n",
       "<tr><td>maxs   </td><td>7.7               </td><td>4.4                </td><td>6.9               </td><td>2.5               </td><td>           </td></tr>\n",
       "<tr><td>sigma  </td><td>0.8227432306536366</td><td>0.42693963666333795</td><td>1.7322189636705823</td><td>0.7548240149517819</td><td>           </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>           </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0          </td></tr>\n",
       "<tr><td>0      </td><td>4.7               </td><td>3.2                </td><td>1.3               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>1      </td><td>4.6               </td><td>3.1                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>2      </td><td>5.0               </td><td>3.6                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>3      </td><td>5.4               </td><td>3.9                </td><td>1.7               </td><td>0.4               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>4      </td><td>4.6               </td><td>3.4                </td><td>1.4               </td><td>0.3               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>5      </td><td>5.0               </td><td>3.4                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>6      </td><td>4.4               </td><td>2.9                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>7      </td><td>5.4               </td><td>3.7                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>8      </td><td>4.8               </td><td>3.4                </td><td>1.6               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
       "<tr><td>9      </td><td>4.8               </td><td>3.0                </td><td>1.4               </td><td>0.1               </td><td>Iris-setosa</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mGBM = H2OGradientBoostingEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "mGBM.train([\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\"], \"class\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1543927455262_1\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.002790592010464094\n",
      "RMSE: 0.052826054276882105\n",
      "LogLoss: 0.017476272904586188\n",
      "Mean Per-Class Error: 0.0\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>37.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 37</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>42.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 42</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 40</td></tr>\n",
       "<tr><td>37.0</td>\n",
       "<td>42.0</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 119</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error    Rate\n",
       "-------------  -----------------  ----------------  -------  -------\n",
       "37             0                  0                 0        0 / 37\n",
       "0              42                 0                 0        0 / 42\n",
       "0              0                  40                0        0 / 40\n",
       "37             42                 40                0        0 / 119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    1\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:27</td>\n",
       "<td> 0.150 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>1.0986123</td>\n",
       "<td>0.6218487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:28</td>\n",
       "<td> 0.508 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6031805</td>\n",
       "<td>0.9246870</td>\n",
       "<td>0.0336134</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:28</td>\n",
       "<td> 0.653 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.5454041</td>\n",
       "<td>0.7893513</td>\n",
       "<td>0.0336134</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:28</td>\n",
       "<td> 0.792 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4927540</td>\n",
       "<td>0.6797675</td>\n",
       "<td>0.0336134</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:28</td>\n",
       "<td> 0.830 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4449532</td>\n",
       "<td>0.5890979</td>\n",
       "<td>0.0336134</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:30</td>\n",
       "<td> 2.706 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0600134</td>\n",
       "<td>0.0214302</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:30</td>\n",
       "<td> 2.718 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.0587942</td>\n",
       "<td>0.0206212</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:30</td>\n",
       "<td> 2.729 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.0575721</td>\n",
       "<td>0.0197567</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:30</td>\n",
       "<td> 2.748 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.0535618</td>\n",
       "<td>0.0181288</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-04 12:44:30</td>\n",
       "<td> 2.770 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0528261</td>\n",
       "<td>0.0174763</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse         training_logloss      training_classification_error\n",
       "---  -------------------  ----------  -----------------  --------------------  --------------------  -------------------------------\n",
       "     2018-12-04 12:44:27  0.150 sec   0.0                0.6666666666666659    1.0986122886681082    0.6218487394957983\n",
       "     2018-12-04 12:44:28  0.508 sec   1.0                0.6031805382417712    0.9246869938231496    0.03361344537815126\n",
       "     2018-12-04 12:44:28  0.653 sec   2.0                0.5454040732554468    0.7893512590747551    0.03361344537815126\n",
       "     2018-12-04 12:44:28  0.792 sec   3.0                0.49275402233057874   0.6797675391579704    0.03361344537815126\n",
       "     2018-12-04 12:44:28  0.830 sec   4.0                0.44495324523092744   0.5890978745086636    0.03361344537815126\n",
       "---  ---                  ---         ---                ---                   ---                   ---\n",
       "     2018-12-04 12:44:30  2.706 sec   46.0               0.06001341451029571   0.021430215560784983  0.0\n",
       "     2018-12-04 12:44:30  2.718 sec   47.0               0.05879419095824852   0.020621230542014195  0.0\n",
       "     2018-12-04 12:44:30  2.729 sec   48.0               0.057572075071915925  0.019756668421347927  0.0\n",
       "     2018-12-04 12:44:30  2.748 sec   49.0               0.05356180550196325   0.018128765206245217  0.0\n",
       "     2018-12-04 12:44:30  2.770 sec   50.0               0.052826054276882105  0.017476272904586188  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>petal_len</td>\n",
       "<td>216.7495117</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5932508</td></tr>\n",
       "<tr><td>petal_wid</td>\n",
       "<td>144.4012146</td>\n",
       "<td>0.6662124</td>\n",
       "<td>0.3952311</td></tr>\n",
       "<tr><td>sepal_wid</td>\n",
       "<td>2.6983480</td>\n",
       "<td>0.0124492</td>\n",
       "<td>0.0073855</td></tr>\n",
       "<tr><td>sepal_len</td>\n",
       "<td>1.5098836</td>\n",
       "<td>0.0069660</td>\n",
       "<td>0.0041326</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "petal_len   216.75                 1                    0.593251\n",
       "petal_wid   144.401                0.666212             0.395231\n",
       "sepal_wid   2.69835                0.0124492            0.00738547\n",
       "sepal_len   1.50988                0.00696603           0.0041326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "p = mGBM.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict    </th><th style=\"text-align: right;\">  Iris-setosa</th><th style=\"text-align: right;\">  Iris-versicolor</th><th style=\"text-align: right;\">  Iris-virginica</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.998982</td><td style=\"text-align: right;\">      0.000503086</td><td style=\"text-align: right;\">     0.000515137</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.998809</td><td style=\"text-align: right;\">      0.000641481</td><td style=\"text-align: right;\">     0.000549225</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.998808</td><td style=\"text-align: right;\">      0.000641654</td><td style=\"text-align: right;\">     0.000550001</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.99881 </td><td style=\"text-align: right;\">      0.000641202</td><td style=\"text-align: right;\">     0.000548929</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.997835</td><td style=\"text-align: right;\">      0.00177245 </td><td style=\"text-align: right;\">     0.000392934</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.997863</td><td style=\"text-align: right;\">      0.0017717  </td><td style=\"text-align: right;\">     0.000365617</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.998689</td><td style=\"text-align: right;\">      0.000796088</td><td style=\"text-align: right;\">     0.000514672</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.99835 </td><td style=\"text-align: right;\">      0.00116748 </td><td style=\"text-align: right;\">     0.000482465</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.998334</td><td style=\"text-align: right;\">      0.00116516 </td><td style=\"text-align: right;\">     0.000500533</td></tr>\n",
       "<tr><td>Iris-setosa</td><td style=\"text-align: right;\">     0.99871 </td><td style=\"text-align: right;\">      0.000775037</td><td style=\"text-align: right;\">     0.000514883</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.03304693797784583\n",
      "RMSE: 0.1817881678708651\n",
      "LogLoss: 0.18288111583643185\n",
      "Mean Per-Class Error: 0.041666666666666664\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Iris-setosa</b></td>\n",
       "<td><b>Iris-versicolor</b></td>\n",
       "<td><b>Iris-virginica</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>13.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 13</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>7.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.125</td>\n",
       "<td>1 / 8</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 10</td></tr>\n",
       "<tr><td>13.0</td>\n",
       "<td>7.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0322581</td>\n",
       "<td>1 / 31</td></tr></table></div>"
      ],
      "text/plain": [
       "Iris-setosa    Iris-versicolor    Iris-virginica    Error      Rate\n",
       "-------------  -----------------  ----------------  ---------  ------\n",
       "13             0                  0                 0          0 / 13\n",
       "0              7                  1                 0.125      1 / 8\n",
       "0              0                  10                0          0 / 10\n",
       "13             7                  11                0.0322581  1 / 31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9677419</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.967742\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mGBM.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGradientBoostingEstimator in module h2o.estimators.gbm:\n",
      "\n",
      "class H2OGradientBoostingEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  H2OGradientBoostingEstimator(**kwargs)\n",
      " |  \n",
      " |  Gradient Boosting Machine\n",
      " |  \n",
      " |  Builds gradient boosted trees on a parsed data set, for regression or classification.\n",
      " |  The default distribution function will guess the model type based on the response column type.\n",
      " |  Otherwise, the response column must be an enum for \"bernoulli\" or \"multinomial\", and numeric\n",
      " |  for all other distributions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGradientBoostingEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  build_tree_one_node\n",
      " |      Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  calibrate_model\n",
      " |      Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more accurate estimates\n",
      " |      of class probabilities.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  calibration_frame\n",
      " |      Calibration frame for Platt Scaling\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  categorical_encoding\n",
      " |      Encoding scheme for categorical features\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"enum\"``, ``\"one_hot_internal\"``, ``\"one_hot_explicit\"``, ``\"binary\"``, ``\"eigen\"``,\n",
      " |      ``\"label_encoder\"``, ``\"sort_by_response\"``, ``\"enum_limited\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  checkpoint\n",
      " |      Model checkpoint to resume training with.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  col_sample_rate\n",
      " |      Column sample rate (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  col_sample_rate_change_per_level\n",
      " |      Relative change of the column sampling rate for every level (must be > 0.0 and <= 2.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  col_sample_rate_per_tree\n",
      " |      Column sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  custom_metric_func\n",
      " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  distribution\n",
      " |      Distribution function\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"bernoulli\"``, ``\"quasibinomial\"``, ``\"multinomial\"``, ``\"gaussian\"``, ``\"poisson\"``,\n",
      " |      ``\"gamma\"``, ``\"tweedie\"``, ``\"laplace\"``, ``\"quantile\"``, ``\"huber\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  histogram_type\n",
      " |      What type of histogram to use for finding optimal split points\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"uniform_adaptive\"``, ``\"random\"``, ``\"quantiles_global\"``, ``\"round_robin\"``  (default:\n",
      " |      ``\"auto\"``).\n",
      " |  \n",
      " |  huber_alpha\n",
      " |      Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and 1).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.9``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_models\n",
      " |      Whether to keep the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  learn_rate\n",
      " |      Learning rate (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.1``).\n",
      " |  \n",
      " |  learn_rate_annealing\n",
      " |      Scale the learning rate by this factor after each tree (e.g., 0.99 or 0.999)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  max_abs_leafnode_pred\n",
      " |      Maximum absolute value of a leaf node prediction\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_depth\n",
      " |      Maximum tree depth.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``5``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  min_rows\n",
      " |      Fewest allowed (weighted) observations in a leaf.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``10``).\n",
      " |  \n",
      " |  min_split_improvement\n",
      " |      Minimum relative improvement in squared error reduction for a split to happen\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-05``).\n",
      " |  \n",
      " |  nbins\n",
      " |      For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  nbins_cats\n",
      " |      For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher\n",
      " |      values can lead to more overfitting.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |  \n",
      " |  nbins_top_level\n",
      " |      For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then decrease\n",
      " |      by factor of two per level\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  ntrees\n",
      " |      Number of trees.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``50``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  pred_noise_bandwidth\n",
      " |      Bandwidth (sigma) of Gaussian multiplicative noise ~N(1,sigma) for tree node predictions\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  quantile_alpha\n",
      " |      Desired quantile for Quantile regression, must be between 0 and 1.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.5``).\n",
      " |  \n",
      " |  r2_stopping\n",
      " |      r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric and\n",
      " |      stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or\n",
      " |      exceeds this\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  sample_rate\n",
      " |      Row sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  sample_rate_per_class\n",
      " |      A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  score_tree_interval\n",
      " |      Score the model after every so many trees. Disabled if set to 0.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  stopping_metric\n",
      " |      Metric to use for early stopping (AUTO: logloss for classification, deviance for regression)\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"deviance\"``, ``\"logloss\"``, ``\"mse\"``, ``\"rmse\"``, ``\"mae\"``, ``\"rmsle\"``, ``\"auc\"``,\n",
      " |      ``\"lift_top_group\"``, ``\"misclassification\"``, ``\"mean_per_class_error\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  stopping_rounds\n",
      " |      Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the\n",
      " |      stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  stopping_tolerance\n",
      " |      Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.001``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  tweedie_power\n",
      " |      Tweedie power for Tweedie regression, must be between 1 and 2.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.5``).\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
      " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
      " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'gbm'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
      " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
      " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
      " |      \n",
      " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
      " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
      " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
      " |      \n",
      " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
      " |      \n",
      " |      1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
      " |      h2oModelD = H2OXGBoostEstimator(**h2oParamsD) # parameters specified as a dict()\n",
      " |      h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
      " |      h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
      " |      \n",
      " |      2. Derive the DMatrix from H2OFrame:\n",
      " |      nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
      " |      \n",
      " |      3. Derive the parameters for native XGBoost:\n",
      " |      nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
      " |      \n",
      " |      4. Train your native XGBoost model and generate a prediction:\n",
      " |      nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
      " |      nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1].\n",
      " |      \n",
      " |      5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
      " |      \n",
      " |      :return: nativeParams, num_boost_round\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
      " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
      " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |      into cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
      " |      of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  staged_predict_proba(self, test_data)\n",
      " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
      " |      \n",
      " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
      " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
      " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
      " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of staged predictions.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(h2o.estimators.gbm.H2OGradientBoostingEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
